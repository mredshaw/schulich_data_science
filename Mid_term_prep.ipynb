{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1/main/sales_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.info()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating descriptive statistic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,89,87,65,34,98,87,65]\n",
    "#create mean function\n",
    "def mean(x):\n",
    "    return sum(x)/len(x)\n",
    "mean(list1)\n",
    "\n",
    "#create median function\n",
    "\n",
    "def median(x):\n",
    "    sorted(x) # works on any sequential object\n",
    "    if len(x)%2 == 0:\n",
    "        med = (x[(len(x)//2)]+x[(len(x)//2)-1])/2\n",
    "    else:\n",
    "        med = x[len(x)//2]\n",
    "\n",
    "    return med\n",
    "\n",
    "median(list1)\n",
    "\n",
    "\n",
    "#create mode function\n",
    "\n",
    "def mode(x):\n",
    "    freq_dict = {}\n",
    "    for i in x:\n",
    "        if i in freq_dict:\n",
    "            freq_dict[i] += 1\n",
    "        else:\n",
    "            freq_dict[i] = 1\n",
    "\n",
    "    # Find the mode(s)\n",
    "    max_freq = max(freq_dict.values())\n",
    "    modes = [k for k, v in freq_dict.items() if v == max_freq]\n",
    "    \n",
    "    return modes\n",
    "\n",
    "mode(list1)\n",
    "\n",
    "#create quartile determining function\n",
    "\n",
    "def iqr(x):\n",
    "    x.sort()\n",
    "    first_quartile_val = min(x)\n",
    "    second_quartile_val = x[len(x)//4]\n",
    "    third_quartile_val = x[(len(x)//4) * 2]\n",
    "    fourth_quartile_val = x[(len(x)//4) * 3]\n",
    "    list_quartiles = [first_quartile_val, second_quartile_val, third_quartile_val, fourth_quartile_val]\n",
    "\n",
    "    return list_quartiles\n",
    "\n",
    "iqr(list1)\n",
    "\n",
    "#Find iqr_range\n",
    "\n",
    "iqr_range = iqr(list1)[-1] - iqr(list1)[1]\n",
    "print(iqr_range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using np to do descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures of central tendency\n",
    "mean = np.mean(data)\n",
    "median = np.median(data)\n",
    "mode = scipy.stats.mode(data)\n",
    "\n",
    "# Measures of dispersion\n",
    "range_value = np.ptp(data)\n",
    "variance = np.var(data)\n",
    "std_dev = np.std(data)\n",
    "iqr = scipy.stats.iqr(data)\n",
    "\n",
    "# Skewness and kurtosis\n",
    "skew = scipy.stats.skew(data)\n",
    "kurtosis = scipy.stats.kurtosis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate skewness of a data set\n",
    "def skewness(data):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum((x - mean) ** 2 for x in data) / n\n",
    "    std_dev = math.sqrt(variance)\n",
    "    \n",
    "    skewness = sum((x - mean) ** 3 for x in data) / (n * std_dev ** 3)\n",
    "    return skewness\n",
    "\n",
    "#another method\n",
    "\n",
    "scipy.stats.skew(list1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using np to calculate correlation and scipy to calculate spearmans correlation.\n",
    "\n",
    "Pearson's correlation measures linear relationship between variables, Spearman's correlation measures monotonic relationship (whether the increase in one variable corresponds to the increase in another variable, not necessarily at a constant rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.corrcoef(x, y)[0, 1])  \n",
    "print(np.cov(x, y)[0, 1]) \n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print(spearmanr(x, y).correlation) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual representations syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCATTERPLOT\n",
    "data = pd.DataFrame({\n",
    "    'x': x,\n",
    "    'y': y\n",
    "})\n",
    "\n",
    "sns.scatterplot(data=data, x='x', y='y')   #Deciding the dataframe, and the columns being used per axis\n",
    "\n",
    "#HISTPLOT\n",
    "sns.histplot(positive_skew)\n",
    "plt.title('Positive Skew')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning tactics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if row has all these columns with missing values\n",
    "\n",
    "df[df['Product'].isnull() & df['Region'].isnull() & df['Price'].isnull() & df['Units Sold'].isnull()]\n",
    "\n",
    "# Checking if they have any rows with the following columns w missing values\n",
    "df[df['Product'].isnull() & df['Region'].isnull() & df['Price'].isnull()]\n",
    "\n",
    "#Rows with just product and region missing\n",
    "\n",
    "df[df['Product'].isnull() & df['Region'].isnull()]\n",
    "\n",
    "#To drop these rows\n",
    "\n",
    "df.drop(df[df['Product'].isnull() & df['Region'].isnull()].index, axis=0, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows based on row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping row index 7 and 22\n",
    "\n",
    "df.drop([7,22], axis=0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy of the dataframe for texting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain descriptive stats based on grouping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby('Region').describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in data with a specific value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Region'] = df_test['Region'].fillna('Other') #Filling na region values with 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data= df, x = 'column1', y='column2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covered topics:\n",
    "\n",
    "Descriptive statistics\n",
    "Data cleaning techniques and analysis\n",
    "Hypothesis testing structure and types of tests + when to use them\n",
    "Experiment design\n",
    "Experiment results analysis\n",
    "Feature engineering\n",
    "Dimensionality reduction (PCA)\n",
    "Interpretation of analysis result; ability to make actionable recommendations to a business"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 coding problem\n",
    "You will be provided a dataset and a general problem statement / scenario\n",
    "You will be required to analyze the dataset using techniques covered in class, and make a final recommendation to the business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
